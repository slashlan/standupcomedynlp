{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232edf0d",
   "metadata": {},
   "source": [
    "# 5) Conclusions\n",
    "\n",
    "This analysis aimed at exploring the content of stand-up comedy scripts from Netflix and Amazon and testing the language generation capabilites of a RNN model trained on this type of texts.\n",
    "\n",
    "Section 1 showed how the stand-up comedy dataset for the analysis has been built using freely available data sources from the internet.\n",
    "\n",
    "Section 2 (EDA) and 3 (Topic Modelling) showed that stand-up comedy shows are very much a cultural phenomenon diffused in English-speaking countries and for this reason very much linked to this same countries in terms of cultural, political and geographical references. The most common topics discussed by stand-up comedians are by far anecdotes about personal experiences, daily-life situations and family, followed by satire on politicians, national & religious groups and on sex/relationships. What also emerged during topic modelling is that the extent and diversity of the \"personal anecdotes\" topic category in terms of stories/characters involved makes the data very noisy and it is therefore not possible to breakdown this class in a smaller number of neat and defined topics. Furthermore, the fact that most comedians tackle a mix of topics in each show (from personal stories, to politics and sex) complicates making this distinction even more.\n",
    "\n",
    "In Section 4, I used a subsample of the stand up comedy scripts to build training and validation features sets to feed into 2 RNN models based on different architectures. After this, the most accurate model has been employed to generate new text. The analysis showed that training language models and reaching high levels of accuracy is both computationally very expensive and data intensive, particularly when dealing with complex texts (i.e., rich vocabulary per given amount of text) such as stand-up comedy scripts. Nevertheless, despite the presence of these technical challenges, the RNN models produced were on average 3 times more accurate in predicting the next word in a sentence than using the simple baseline model based on the principle \"use the most frequent word in the vocabulary to predict the next word in a sentence\". \n",
    "\n",
    "Finally, the comparison between the new generated text by the model and the actual sequence of text shows that the RNN models built are still far from being able to generate meaningful human-like text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
